Oligotyping: QIIME and R Code

=================================================================
ssh bv32@headnode.beocat.ksu.edu
conda activate qiime2-amplicon-2024.5
===================================================================
Local Soil:

cd /bulk/leet1/Share_LeeLab/Andropogon_microbiome/00_Old_Soil_and_Root/00_BS_Soil_Redo


1. Export representative sequences
Export the representative sequences (rep-seqs.qza) into a standard FASTA format.
bash
CopyEdit
qiime tools export \
  --input-path rep-seqs.qza \
  --output-path exported-rep-seqs-2

Input: rep-seqs.qza
Output: FASTA file at exported-rep-seqs-2/dna-sequences.fasta

2. Export the feature table and convert it to TSV format
Export the feature table (table.qza) and convert it to a tabular format.
bash
CopyEdit
qiime tools export \
  --input-path table.qza \
  --output-path exported-feature-table

biom convert \
  -i exported-feature-table/feature-table.biom \
  -o feature-table.tsv \
  --to-tsv

Input: table.qza (feature table)
Output: feature-table.tsv (tab-delimited table)

3. Submit a job to format FASTA headers
Run a batch script to reformat FASTA headers based on metadata and sample mapping.
Batch Script (format_fasta_job.sh)
bash
CopyEdit
#!/bin/bash -l
#SBATCH --job-name=BS_Soil_Tree
#SBATCH --mem-per-cpu=4G   
#SBATCH --time=1-00:00:00   
#SBATCH --ntasks=10
#SBATCH --nodes=1
#SBATCH --mail-user=bv32@ksu.edu
#SBATCH --mail-type=ALL   

# Navigate to the working directory
cd /bulk/leet1/Share_LeeLab/Andropogon_microbiome/00_Old_Soil_and_Root/00_BS_Soil_Redo

# Load Conda environment
source /homes/bv32/miniconda3/etc/profile.d/conda.sh
conda activate qiime2-amplicon-2024.5

# Define input/output files
FASTA_FILE="exported-rep-seqs-2/dna-sequences.fasta"
METADATA_FILE="BS_Soil_Metadata.tsv"
OUTPUT_FASTA="formatted_sequences.fasta"

# Ensure required files exist
if [ ! -f "$FASTA_FILE" ]; then
    echo "Error: FASTA file '$FASTA_FILE' not found."
    exit 1
fi

if [ ! -f "$METADATA_FILE" ]; then
    echo "Error: Metadata file '$METADATA_FILE' not found."
    exit 1
fi

# Check if metadata contains sample-id
if ! grep -q "sample-id" "$METADATA_FILE"; then
    echo "Error: Metadata file must have a 'sample-id' column."
    exit 1
fi

# Generate a temporary map file with sample-id and sequential numbering
TMP_MAP_FILE=$(mktemp)
awk 'NR>1 {print $1}' "$METADATA_FILE" | nl -n rz -w 2 | awk '{print $2 "\tSample-" sprintf("%02d", $1)}' > "$TMP_MAP_FILE"

# Format the FASTA file
echo "Formatting FASTA headers based on metadata..."
awk -v map="$TMP_MAP_FILE" '
  BEGIN {
    # Load sample-id-to-Sample-N mapping
    while ((getline line < map) > 0) {
      split(line, arr, "\t")
      sample_map[arr[1]] = arr[2]
    }
  }
  /^>/ {
    # Process FASTA headers
    header = substr($0, 2)
    split(header, id_parts, "_")
    sample_id = id_parts[1]
    read_id = id_parts[2]
    if (sample_map[sample_id] != "") {
      print ">" sample_map[sample_id] "_" read_id
    } else {
      print ">" header
    }
  }
  /^[^>]/ {
    # Print sequence
    print $0
  }
' "$FASTA_FILE" > "$OUTPUT_FASTA"

# Clean up temporary files
rm -f "$TMP_MAP_FILE"

echo "Formatted FASTA saved as '$OUTPUT_FASTA'."

Purpose: This script reformats FASTA headers based on metadata.
Output: Reformatted FASTA file (formatted_sequences.fasta).
Submit the script using:
bash
CopyEdit
sbatch format_fasta_job.sh


4. Map features to samples
Map features from the feature-table.tsv file to their respective samples.
bash
CopyEdit
awk 'NR==1 {print; next} {for (i=2; i<=NF; i++) if ($i > 0) print $1, i-1}' feature-table.tsv > feature-to-sample-map.txt

Input: feature-table.tsv
Output: feature-to-sample-map.txt (maps features to sample IDs)

5. Assign sample IDs to FASTA headers
Update the FASTA file to include sample IDs in headers using the generated map file.
bash
CopyEdit
awk 'NR==FNR {map[$1]=$2; next} /^>/ {header = substr($0, 2); print ">" map[header]; next} {print}' \
    feature-to-sample-map.txt \
    exported-rep-seqs-2/dna-sequences.fasta > formatted_sequences.fasta

Input: feature-to-sample-map.txt, exported-rep-seqs-2/dna-sequences.fasta
Output: formatted_sequences.fasta
>144
AACACATCGGTCAGGCGGTAATTGGTTTAACTTGGTGTAAACATATGTAGATGGTTTAATAATTAATTTATAAAAGGCTAGAATAAAATACTTATAGAGACGGTAAATTAGGAATATTAAACTAGACGATAGAAAAGATGATAAAAGAAAAATATTGAAGATTTAATATGCTATTATAAGAATTTGAAGTACCATGGTGTGAAGACATTTATCAATAATATCGCGACATTGAGATATGAAAGCTCGGGGAGCAAAATGGATTCGAAACCC

6. Append read counts to headers
Ensure multiple features mapped to the same sample have unique headers (e.g., Sample-144_Read1, Sample-144_Read2).
bash
CopyEdit
awk '/^>/ {
    header_count[$1]++;  # Count the occurrences of each header
    sample_id = "Sample-" substr($1, 2);  # Format the header with Sample-
    print ">" sample_id "_Read" header_count[$1];  # Append Read count to the header
} 
/^[^>]/ {
    print $0;  # Print the sequence as-is
}' formatted_sequences.fasta > formatted_sequences3.fasta

Input: formatted_sequences.fasta
Output: formatted_sequences3.fasta
>Sample-144_Read1
AACACATCGGTCAGGCGGTAATTGGTTTAACTTGGTGTAAACATATGTAGATGGTTTAATAATTAATTTATAAAAGGCTAGAATAAAATACTTATAGAGACGGTAAATTAGGAATATTAAACTAGACGATAGAAAAGATGATAAAAGAAAAATATTGAAGATTTAATATGCTATTATAAGAATTTGA

7. Extract sample information
Run the o-get-sample-info-from-fasta tool to retrieve sample information.
bash
CopyEdit
o-get-sample-info-from-fasta formatted_sequences3.fasta

Input: formatted_sequences3.fasta
Output: Sample information extracted from the FASTA headers.
Total number of samples:  157
Total number of reads:  41,709
Samples and read counts found in the FASTA file:
Sample-139                     774
Sample-157                     612
Sample-86                      594
Sample-151                     556
Sample-156                     532
Sample-87                      481
Sample-150                     462
Sample-126                     461
Sample-31                      438
Sample-55                      413
Sample-121                     412
Sample-117                     403
Sample-123                     397
Sample-56                      393
Sample-147                     385
Sample-124                     383
Sample-122                     383
Sample-154                     382
Sample-127                     379
Sample-91                      366
Sample-90                      359
Sample-125                     359
Sample-149                     355
Sample-145                     346
Sample-76                      345
Sample-109                     343
Sample-148                     342
Sample-78                      332
Sample-116                     324
Sample-100                     324
Sample-33                      319
Sample-138                     319
Sample-118                     316
Sample-60                      315
Sample-58                      314
Sample-155                     310
Sample-114                     310
Sample-119                     308
Sample-142                     307
Sample-153                     306
Sample-143                     303
Sample-112                     299
Sample-115                     299
Sample-101                     298
Sample-88                      298
Sample-49                      297
Sample-84                      292
Sample-113                     291
Sample-128                     290
Sample-146                     290
Sample-16                      289
Sample-96                      284
Sample-129                     282
Sample-27                      281
Sample-29                      279
Sample-19                      279
Sample-59                      277
Sample-64                      276
Sample-83                      276
Sample-93                      275
Sample-34                      275
Sample-98                      274
Sample-152                     273
Sample-102                     273
Sample-120                     272
Sample-110                     270
Sample-35                      268
Sample-69                      268
Sample-72                      268
Sample-28                      267
Sample-144                     266
Sample-89                      266
Sample-97                      263
Sample-67                      262
Sample-82                      261
Sample-94                      258
Sample-18                      254
Sample-21                      254
Sample-57                      254
Sample-92                      250
Sample-20                      250
Sample-141                     250
Sample-32                      248
Sample-106                     248
Sample-36                      246
Sample-111                     244
Sample-63                      243
Sample-14                      243
Sample-42                      242
Sample-68                      242
Sample-95                      242
Sample-77                      236
Sample-24                      236
Sample-133                     235
Sample-103                     235
Sample-81                      234
Sample-11                      234
Sample-10                      234
Sample-70                      229
Sample-7                       229
Sample-50                      228
Sample-132                     228
Sample-107                     225
Sample-71                      225
Sample-105                     224
Sample-53                      224
Sample-140                     223
Sample-51                      223
Sample-80                      222
Sample-135                     222
Sample-99                      221
Sample-79                      220
Sample-108                     219
Sample-137                     213
Sample-41                      213
Sample-66                      212
Sample-23                      211
Sample-130                     211
Sample-22                      203
Sample-75                      201
Sample-15                      199
Sample-52                      198
Sample-1                       193
Sample-65                      191
Sample-30                      189
Sample-131                     189
Sample-73                      189
Sample-2                       186
Sample-13                      185
Sample-61                      182
Sample-25                      180
Sample-54                      177
Sample-17                      176
Sample-104                     176
Sample-134                     176
Sample-40                      175
Sample-8                       169
Sample-45                      169
Sample-46                      168
Sample-74                      166
Sample-6                       165
Sample-62                      164
Sample-37                      163
Sample-136                     155
Sample-4                       155
Sample-44                      145
Sample-9                       144
Sample-26                      143
Sample-12                      140
Sample-47                      129
Sample-38                      129
Sample-48                      122
Sample-3                       121
Sample-43                      98
Sample-39                      66
Sample-5                       51
Sample-85                      8

8. Align the FASTA Sequences from the Reads
Use muscle to align the FASTA sequences.
bash
CopyEdit
conda install -c bioconda muscle

sbatch muscle_alignment6.sh

muscle_alignment6.sh

#!/bin/bash -l
#SBATCH --job-name=muscle_alignment
#SBATCH --mem=128G                # Request 128 GB of memory
#SBATCH --time=3-00:00:00         # Request 3 days of wall time
#SBATCH --ntasks=1                # Use a single task
#SBATCH --cpus-per-task=16        # Use 16 CPU cores
#SBATCH --output=muscle_output.log  # Log file for STDOUT
#SBATCH --error=muscle_error.log    # Log file for STDERR
#SBATCH --mail-user=bv32@ksu.edu
#SBATCH --mail-type=ALL 

# Working directory
cd /bulk/leet1/Share_LeeLab/Andropogon_microbiome/00_Old_Soil_and_Root/00_BS_Soil_Redo

# Load Conda environment
source /homes/bv32/miniconda3/etc/profile.d/conda.sh
conda activate qiime2-amplicon-2024.5

# Set input and output files
INPUT_FASTA="formatted_sequences3.fasta"
OUTPUT_FASTA="aligned_sequences.fasta"

# Check if the input file exists
if [ ! -f "$INPUT_FASTA" ]; then
    echo "Error: Input FASTA file '$INPUT_FASTA' not found."
    exit 1
fi

# Run MUSCLE with the Super5 algorithm
echo "Starting MUSCLE alignment with -super5..."
muscle -super5 "$INPUT_FASTA" -output "$OUTPUT_FASTA"

# Check for successful completion
if [ $? -eq 0 ]; then
    echo "MUSCLE alignment completed successfully."
else
    echo "Error: MUSCLE alignment failed."
    exit 1
fi
Input: formatted_sequences3.fasta
Output: aligned_sequences.fasta

9. Entropy and Oligotyping
Check to see that all of the reads are the same length
awk '/^>/ {if (seqlen){print seqlen}; printf $0"\t"; seqlen=0; next} {seqlen += length($0)} END {print seqlen}' aligned_sequences.fasta
	
2493

Make sure that there are not any ambiguous nucleotides in your sequence:

grep -o "N" aligned_sequences.fasta | wc -l
	
0

Run entropy and oligotyping analysis:

sbatch entropy_analysis6.sh

#!/bin/bash -l
#SBATCH --job-name=entropy_and_oligotype_analysis
#SBATCH --mem=64G                # Request 64 GB of memory
#SBATCH --time=1-00:00:00        # Request 1 day of wall time
#SBATCH --ntasks=1               # Use a single task
#SBATCH --cpus-per-task=8        # Use 8 CPU cores
#SBATCH --output=entropy_oligotype_output.log  # Log file for STDOUT
#SBATCH --error=entropy_oligotype_error.log    # Log file for STDERR
#SBATCH --mail-user=bv32@ksu.edu
#SBATCH --mail-type=ALL 

# Working directory
cd /bulk/leet1/Share_LeeLab/Andropogon_microbiome/00_Old_Soil_and_Root/00_BS_Soil_Redo

# Load Conda environment
source /homes/bv32/miniconda3/etc/profile.d/conda.sh
conda activate qiime2-amplicon-2024.5

# Set input and output files
INPUT_FASTA="aligned_sequences.fasta"
OUTPUT_DIR="entropy_results_new"
OLIGOTYPE_OUTPUT_DIR="oligotype_results_new"

# Check if the input file exists
if [ ! -f "$INPUT_FASTA" ]; then
    echo "Error: Input FASTA file '$INPUT_FASTA' not found."
    exit 1
fi

# Create output directories if they don't exist
mkdir -p "$OUTPUT_DIR"
mkdir -p "$OLIGOTYPE_OUTPUT_DIR"

# Run entropy analysis
echo "Starting entropy analysis on '$INPUT_FASTA'..."
entropy-analysis "$INPUT_FASTA"

if [ $? -eq 0 ]; then
    echo "Entropy analysis completed successfully. Moving results to '$OUTPUT_DIR'..."
    mv "${INPUT_FASTA}-ENTROPY" "$OUTPUT_DIR/"
    mv "${INPUT_FASTA}-ENTROPY.png" "$OUTPUT_DIR/"
else
    echo "Error: Entropy analysis failed."
    exit 1
fi

# Define paths for oligotyping
ENTROPY_FILE="$OUTPUT_DIR/${INPUT_FASTA}-ENTROPY"
OLIGOTYPE_INPUT_FASTA="$INPUT_FASTA"
OLIGOTYPE_OUTPUT_FASTA="$OLIGOTYPE_OUTPUT_DIR/oligotype-representative-sequences.fasta"
OLIGOTYPE_ABUNDANCE_TABLE="$OLIGOTYPE_OUTPUT_DIR/oligotype-abundance.csv"

# Run oligotyping
echo "Starting oligotyping on '$OLIGOTYPE_INPUT_FASTA' with entropy file '$ENTROPY_FILE'..."
oligotype "$OLIGOTYPE_INPUT_FASTA" "$ENTROPY_FILE" -c 7 -M 1

if [ $? -eq 0 ]; then
    echo "Oligotyping completed successfully."
    mv "${OLIGOTYPE_INPUT_FASTA}-OLIGOTYPES.fasta" "$OLIGOTYPE_OUTPUT_FASTA"
    mv "${OLIGOTYPE_INPUT_FASTA}-OLIGOTYPES-ABUNDANCE.csv" "$OLIGOTYPE_ABUNDANCE_TABLE"
    echo "Oligotyping results saved to '$OLIGOTYPE_OUTPUT_DIR'."
else
    echo "Error: Oligotyping failed."
    exit 1
fi

echo "Entropy and oligotype analysis completed successfully."

Input: aligned_sequences.fasta
Output: 
aligned_sequences.fasta-ENTROPY 
OLIGO-REPRESENTATIVES.fasta
MATRIX-COUNT.txt

Rhizobiome:

cd /bulk/leet1/Share_LeeLab/Andropogon_microbiome/00_BS_Root_Final


1. Export representative sequences
Export the representative sequences (rep-seqs.qza) into a standard FASTA format.
bash
CopyEdit
qiime tools export \
  --input-path rep-seqs.qza \
  --output-path exported-rep-seqs-2

Input: rep-seqs.qza
Output: FASTA file at exported-rep-seqs-2/dna-sequences.fasta

2. Export the feature table and convert it to TSV format
Export the feature table (table.qza) and convert it to a tabular format.
bash
CopyEdit
qiime tools export \
  --input-path table.qza \
  --output-path exported-feature-table

biom convert \
  -i exported-feature-table/feature-table.biom \
  -o feature-table.tsv \
  --to-tsv

Input: table.qza (feature table)
Output: feature-table.tsv (tab-delimited table)

3. Submit a job to format FASTA headers
Run a batch script to reformat FASTA headers based on metadata and sample mapping.
CopyEdit
sbatch format_fasta_job_root.sh

#!/bin/bash -l
#SBATCH --job-name=BS_Soil_Tree
#SBATCH --mem-per-cpu=4G   
#SBATCH --time=1-00:00:00   
#SBATCH --ntasks=10
#SBATCH --nodes=1
#SBATCH --mail-user=bv32@ksu.edu
#SBATCH --mail-type=ALL   

# Working directory
cd /bulk/leet1/Share_LeeLab/Andropogon_microbiome/00_BS_Root_Final

# Load Conda environment
source /homes/bv32/miniconda3/etc/profile.d/conda.sh
conda activate qiime2-amplicon-2024.5

# Define input/output files
FASTA_FILE="exported-rep-seqs-2/dna-sequences.fasta"
METADATA_FILE="BS_Root_Metadata.tsv"
OUTPUT_FASTA="formatted_sequences.fasta"

# Ensure required files exist
if [ ! -f "$FASTA_FILE" ]; then
    echo "Error: FASTA file '$FASTA_FILE' not found."
    exit 1
fi

if [ ! -f "$METADATA_FILE" ]; then
    echo "Error: Metadata file '$METADATA_FILE' not found."
    exit 1
fi

# Check if metadata contains sample-id
if ! grep -q "sample-id" "$METADATA_FILE"; then
    echo "Error: Metadata file must have a 'sample-id' column."
    exit 1
fi

# Generate a temporary map file with sample-id and sequential numbering
TMP_MAP_FILE=$(mktemp)
awk 'NR>1 {print $1}' "$METADATA_FILE" | nl -n rz -w 2 | awk '{print $2 "\tSample-" sprintf("%02d", $1)}' > "$TMP_MAP_FILE"

# Format the FASTA file
echo "Formatting FASTA headers based on metadata..."
awk -v map="$TMP_MAP_FILE" '
  BEGIN {
    # Load sample-id-to-Sample-N mapping
    while ((getline line < map) > 0) {
      split(line, arr, "\t")
      sample_map[arr[1]] = arr[2]
    }
  }
  /^>/ {
    # Process FASTA headers
    header = substr($0, 2)
    split(header, id_parts, "_")
    sample_id = id_parts[1]
    read_id = id_parts[2]
    if (sample_map[sample_id] != "") {
      print ">" sample_map[sample_id] "_" read_id
    } else {
      print ">" header
    }
  }
  /^[^>]/ {
    # Print sequence
    print $0
  }
' "$FASTA_FILE" > "$OUTPUT_FASTA"

# Clean up temporary files
rm -f "$TMP_MAP_FILE"

echo "Formatted FASTA saved as '$OUTPUT_FASTA'."
Purpose: This script reformats FASTA headers based on metadata.
Output: Reformatted FASTA file (formatted_sequences.fasta)


4. Map features to samples
Map features from the feature-table.tsv file to their respective samples.
bash
CopyEdit
awk 'NR==1 {print; next} {for (i=2; i<=NF; i++) if ($i > 0) print $1, i-1}' feature-table.tsv > feature-to-sample-map.txt

Input: feature-table.tsv
Output: feature-to-sample-map.txt (maps features to sample IDs)

5. Assign sample IDs to FASTA headers
Update the FASTA file to include sample IDs in headers using the generated map file.
bash
CopyEdit
awk 'NR==FNR {map[$1]=$2; next} /^>/ {header = substr($0, 2); print ">" map[header]; next} {print}' \
    feature-to-sample-map.txt \
    exported-rep-seqs-2/dna-sequences.fasta > formatted_sequences.fasta

Input: feature-to-sample-map.txt, exported-rep-seqs-2/dna-sequences.fasta
Output: formatted_sequences.fasta
>108
AAAGGAAAATGAGTTTTTTCATATTGTGGTGGCTTTGTTGAATACCATGACAAAGTCGGGGGTGACCGTGTAGCATAAAGGTATTACCCTTTCCTGATTATCGACAATAATGCTGCCAACTATCTCACCCCGCGTTTTCTGCGAAAACGGGGCCACTAACAGGCTTTTTGCGAAGGTGAGATCCTTCTTGCCATACACTTTTACCAAGGCTTCTTTGGCGCACCAGTAAATGCAGAGCTTGACCAGGTCCGTGCCGGCGTCGGCCAGCTCGGTGGGGTGGAACATGCGGGGGGCAACGCGCAGCAATTTCTCTTTCGGTTGCTCCAGGTCGATGCCGACCGATTGGTGCGCGTCCAACAGCACGGCGGCGTAGGGAAACGAGTGGCTCAGCGACAGCTGGTAGTCGTGGCCGGCCGGAAAGGGCTTGCCAAAGGCATCTTTG

6. Append read counts to headers
Ensure multiple features mapped to the same sample have unique headers (e.g., Sample-144_Read1, Sample-144_Read2).
bash
CopyEdit
awk '/^>/ {
    header_count[$1]++;  # Count the occurrences of each header
    sample_id = "Sample-" substr($1, 2);  # Format the header with Sample-
    print ">" sample_id "_Read" header_count[$1];  # Append Read count to the header
} 
/^[^>]/ {
    print $0;  # Print the sequence as-is
}' formatted_sequences.fasta > formatted_sequences3.fasta

Input: formatted_sequences.fasta
Output: formatted_sequences3.fasta
>Sample-108_Read1
AAAGGAAAATGAGTTTTTTCATATTGTGGTGGCTTTGTTGAATACCATGACAAAGTCGGGGGTGACCGTGTAGCATAAAGGTATTACCCTTTCCTGATTATCGACAATAATGCTGCCAACTATCTCACCCCGCGTTTTCTGCGAAAACGGGGCCACTAACAGGCTTTTTGCGAAGGTGAGATCCTTCTTGCCATACACTTTTACCAAGGCTTCTTTGGCGCACCAGTAAATGCAGAGCTTGACCAGGTCCGTGCCGGCGTCGGCCAGCTCGGTGGGGTGGAACATGCGGGGGGCAACGCGCAGCAATTTCTCTTTCGGTTGCTCCAGGTCGATGCCGACCGATTGGTGCGCGTCCAACAGCACGGCGGCGTAGGGAAACGAGTGGCTCAGCGACAGCTGGTAGTCGTGGCCGGCCGGAAAGGGCTTGCCAAAGGCATCTTTG

7. Extract sample information
Run the o-get-sample-info-from-fasta tool to retrieve sample information.
bash
CopyEdit
o-get-sample-info-from-fasta formatted_sequences3.fasta

Input: formatted_sequences3.fasta
Output: Sample information extracted from the FASTA headers.
Total number of samples:  150
Total number of reads:  67,678
Samples and read counts found in the FASTA file:
Sample-117                     982
Sample-85                      903
Sample-150                     776
Sample-143                     745
Sample-144                     740
Sample-91                      713
Sample-56                      700
Sample-30                      697
Sample-33                      695
Sample-140                     679
Sample-146                     678
Sample-148                     675
Sample-55                      671
Sample-149                     669
Sample-74                      669
Sample-115                     668
Sample-54                      665
Sample-118                     661
Sample-138                     637
Sample-120                     625
Sample-119                     625
Sample-141                     614
Sample-88                      596
Sample-18                      596
Sample-147                     594
Sample-121                     592
Sample-11                      591
Sample-79                      579
Sample-126                     577
Sample-72                      574
Sample-110                     571
Sample-122                     566
Sample-87                      557
Sample-124                     552
Sample-92                      552
Sample-112                     552
Sample-86                      551
Sample-114                     550
Sample-131                     547
Sample-10                      547
Sample-106                     545
Sample-70                      545
Sample-116                     541
Sample-111                     540
Sample-108                     536
Sample-135                     535
Sample-99                      533
Sample-142                     531
Sample-71                      526
Sample-8                       523
Sample-69                      520
Sample-139                     517
Sample-84                      517
Sample-123                     509
Sample-113                     508
Sample-93                      506
Sample-109                     505
Sample-133                     503
Sample-7                       501
Sample-80                      500
Sample-137                     500
Sample-125                     495
Sample-13                      492
Sample-59                      479
Sample-15                      478
Sample-73                      476
Sample-89                      476
Sample-31                      471
Sample-14                      470
Sample-105                     467
Sample-32                      464
Sample-17                      463
Sample-98                      461
Sample-132                     457
Sample-129                     450
Sample-9                       447
Sample-107                     446
Sample-128                     441
Sample-65                      441
Sample-49                      440
Sample-127                     436
Sample-58                      433
Sample-62                      433
Sample-24                      432
Sample-136                     432
Sample-68                      429
Sample-26                      425
Sample-27                      424
Sample-60                      420
Sample-12                      420
Sample-104                     416
Sample-77                      414
Sample-130                     413
Sample-36                      408
Sample-103                     406
Sample-25                      405
Sample-102                     402
Sample-34                      401
Sample-61                      401
Sample-52                      393
Sample-76                      393
Sample-66                      392
Sample-94                      383
Sample-57                      382
Sample-67                      377
Sample-50                      377
Sample-51                      372
Sample-78                      371
Sample-63                      370
Sample-48                      360
Sample-101                     351
Sample-100                     348
Sample-35                      344
Sample-90                      342
Sample-37                      339
Sample-2                       339
Sample-28                      331
Sample-45                      327
Sample-95                      320
Sample-42                      316
Sample-44                      314
Sample-75                      301
Sample-40                      299
Sample-134                     292
Sample-43                      283
Sample-83                      278
Sample-4                       273
Sample-38                      270
Sample-64                      269
Sample-46                      254
Sample-82                      254
Sample-5                       253
Sample-39                      252
Sample-20                      246
Sample-6                       245
Sample-16                      244
Sample-22                      243
Sample-29                      241
Sample-53                      238
Sample-47                      232
Sample-21                      225
Sample-41                      224
Sample-19                      208
Sample-1                       204
Sample-23                      177
Sample-145                     142
Sample-97                      96
Sample-96                      81
Sample-81                      40
Sample-3                       37

8. Align the FASTA Sequences from the Reads
Use muscle to align the FASTA sequences.
bash
CopyEdit
conda install -c bioconda muscle

sbatch muscle_alignment6_root.sh

#!/bin/bash -l
#SBATCH --job-name=muscle_alignment
#SBATCH --mem=128G                # Request 128 GB of memory
#SBATCH --time=3-00:00:00         # Request 3 days of wall time
#SBATCH --ntasks=1                # Use a single task
#SBATCH --cpus-per-task=16        # Use 16 CPU cores
#SBATCH --output=muscle_output.log  # Log file for STDOUT
#SBATCH --error=muscle_error.log    # Log file for STDERR
#SBATCH --mail-user=bv32@ksu.edu
#SBATCH --mail-type=ALL 

# Working directory
cd /bulk/leet1/Share_LeeLab/Andropogon_microbiome/00_BS_Root_Final

# Load Conda environment
source /homes/bv32/miniconda3/etc/profile.d/conda.sh
conda activate qiime2-amplicon-2024.5

# Set input and output files
INPUT_FASTA="formatted_sequences3.fasta"
OUTPUT_FASTA="aligned_sequences.fasta"

# Check if the input file exists
if [ ! -f "$INPUT_FASTA" ]; then
    echo "Error: Input FASTA file '$INPUT_FASTA' not found."
    exit 1
fi

# Run MUSCLE with the Super5 algorithm
echo "Starting MUSCLE alignment with -super5..."
muscle -super5 "$INPUT_FASTA" -output "$OUTPUT_FASTA"

# Check for successful completion
if [ $? -eq 0 ]; then
    echo "MUSCLE alignment completed successfully."
else
    echo "Error: MUSCLE alignment failed."
    exit 1
fi
Input: formatted_sequences3.fasta
Output: aligned_sequences.fasta

9. Entropy and Oligotyping
Check to see that all of the reads are the same length
awk '/^>/ {if (seqlen){print seqlen}; printf $0"\t"; seqlen=0; next} {seqlen += length($0)} END {print seqlen}' aligned_sequences.fasta
	
4139

Make sure that there are not any ambiguous nucleotides in your sequence:

grep -o "N" aligned_sequences.fasta | wc -l
	
0

Run entropy and oligotyping analysis:

sbatch entropy_analysis6_root.sh

#!/bin/bash -l
#SBATCH --job-name=entropy_and_oligotype_analysis
#SBATCH --mem=64G                # Request 64 GB of memory
#SBATCH --time=1-00:00:00        # Request 1 day of wall time
#SBATCH --ntasks=1               # Use a single task
#SBATCH --cpus-per-task=8        # Use 8 CPU cores
#SBATCH --output=entropy_oligotype_output.log  # Log file for STDOUT
#SBATCH --error=entropy_oligotype_error.log    # Log file for STDERR
#SBATCH --mail-user=bv32@ksu.edu
#SBATCH --mail-type=ALL 

# Working directory
cd /bulk/leet1/Share_LeeLab/Andropogon_microbiome/00_BS_Root_Final

# Load Conda environment
source /homes/bv32/miniconda3/etc/profile.d/conda.sh
conda activate qiime2-amplicon-2024.5

# Set input and output files
INPUT_FASTA="aligned_sequences.fasta"
OUTPUT_DIR="entropy_results_new"
OLIGOTYPE_OUTPUT_DIR="oligotype_results_new"

# Check if the input file exists
if [ ! -f "$INPUT_FASTA" ]; then
    echo "Error: Input FASTA file '$INPUT_FASTA' not found."
    exit 1
fi

# Create output directories if they don't exist
mkdir -p "$OUTPUT_DIR"
mkdir -p "$OLIGOTYPE_OUTPUT_DIR"

# Run entropy analysis
echo "Starting entropy analysis on '$INPUT_FASTA'..."
entropy-analysis "$INPUT_FASTA"

if [ $? -eq 0 ]; then
    echo "Entropy analysis completed successfully. Moving results to '$OUTPUT_DIR'..."
    mv "${INPUT_FASTA}-ENTROPY" "$OUTPUT_DIR/"
    mv "${INPUT_FASTA}-ENTROPY.png" "$OUTPUT_DIR/"
else
    echo "Error: Entropy analysis failed."
    exit 1
fi

# Define paths for oligotyping
ENTROPY_FILE="$OUTPUT_DIR/${INPUT_FASTA}-ENTROPY"
OLIGOTYPE_INPUT_FASTA="$INPUT_FASTA"
OLIGOTYPE_OUTPUT_FASTA="$OLIGOTYPE_OUTPUT_DIR/oligotype-representative-sequences.fasta"
OLIGOTYPE_ABUNDANCE_TABLE="$OLIGOTYPE_OUTPUT_DIR/oligotype-abundance.csv"

# Run oligotyping
echo "Starting oligotyping on '$OLIGOTYPE_INPUT_FASTA' with entropy file '$ENTROPY_FILE'..."
oligotype "$OLIGOTYPE_INPUT_FASTA" "$ENTROPY_FILE" -c 7 -M 1

if [ $? -eq 0 ]; then
    echo "Oligotyping completed successfully."
    mv "${OLIGOTYPE_INPUT_FASTA}-OLIGOTYPES.fasta" "$OLIGOTYPE_OUTPUT_FASTA"
    mv "${OLIGOTYPE_INPUT_FASTA}-OLIGOTYPES-ABUNDANCE.csv" "$OLIGOTYPE_ABUNDANCE_TABLE"
    echo "Oligotyping results saved to '$OLIGOTYPE_OUTPUT_DIR'."
else
    echo "Error: Oligotyping failed."
    exit 1
fi

echo "Entropy and oligotype analysis completed successfully."
Input: aligned_sequences.fasta
Output: 
aligned_sequences.fasta-ENTROPY 
OLIGO-REPRESENTATIVES.fasta
MATRIX-COUNT.txt


